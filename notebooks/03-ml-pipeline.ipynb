{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: \u5f9e Xarray \u5230 ML Pipeline (50 min)\n",
    "\n",
    "\u9019\u500b notebook \u662f\u6574\u500b workshop \u7684\u6838\u5fc3\uff0c\u5c55\u793a\u5982\u4f55\u5c07\u5927\u578b N-D array \u8cc7\u6599\u7121\u7e2b\u6574\u5408\u5230\u6a5f\u5668\u5b78\u7fd2\u6d41\u7a0b\u4e2d\u3002\n",
    "\n",
    "## \u672c\u7bc0\u5167\u5bb9\n",
    "\n",
    "1. **\u5b9a\u7fa9 ML \u4efb\u52d9**\uff1a\u5c0d\u6d41\u5206\u985e\uff08Convection Classification\uff09\n",
    "2. **\u5efa\u7acb Labels**\uff1a\u5f9e CAPE \u5b9a\u7fa9\u5c0d\u6d41\u4e8b\u4ef6\n",
    "3. **xbatcher**\uff1a\u7522\u751f\u8a13\u7df4\u7528\u7684\u6642\u7a7a patches\n",
    "4. **PyTorch \u6574\u5408**\uff1a\u4f7f\u7528 `xbatcher.loaders.torch.MapDataset`\n",
    "5. **\u6a21\u578b\u8a13\u7df4**\uff1a\u7c21\u55ae\u7684 CNN \u5206\u985e\u5668\n",
    "6. **\u7a7a\u9593\u9a57\u8b49**\uff1a\u4f7f\u7528 xskillscore \u8a55\u4f30\u9810\u6e2c\u54c1\u8cea\n",
    "\n",
    "---\n",
    "\n",
    "## \u5b78\u7fd2\u76ee\u6a19\n",
    "\n",
    "- \u7406\u89e3\u300c\u6642\u7a7a batch\u300d\u7684\u6982\u5ff5\n",
    "- \u638c\u63e1 xbatcher \u7684\u5169\u968e\u6bb5\u8a2d\u8a08\uff08BatchGenerator \u2192 MapDataset\uff09\n",
    "- \u6b63\u78ba\u8a2d\u5b9a DataLoader \u53c3\u6578\uff08batch_size=None\uff01\uff09\n",
    "- \u5f9e Xarray \u5230 PyTorch Tensor \u7684\u8cc7\u6599\u6d41\n",
    "- \u4fdd\u7559\u7a7a\u9593\u8cc7\u8a0a\u9032\u884c\u9a57\u8b49\uff08vs \u4e1f\u68c4\u7a7a\u9593\u8cc7\u8a0a\u7684\u50b3\u7d71 ML\uff09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. \u74b0\u5883\u6e96\u5099"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import Client\n",
    "import xarray as xr\n",
    "import xbatcher\n",
    "import intake\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# \u555f\u52d5 Dask Client\n",
    "client = Client(processes=False, n_workers=2, threads_per_worker=2, memory_limit='2GB')\n",
    "print(f\"Dask Dashboard: {client.dashboard_link}\")\n",
    "\n",
    "# \u8f09\u5165 catalog\n",
    "catalog = intake.open_catalog('catalog.yaml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. \u5b9a\u7fa9 ML \u4efb\u52d9\uff1a\u5c0d\u6d41\u5206\u985e\n",
    "\n",
    "### \u4ec0\u9ebc\u662f\u5c0d\u6d41\u5206\u985e\uff1f\n",
    "\n",
    "\u5c0d\u6d41\uff08convection\uff09\u662f\u6307\u7a7a\u6c23\u5782\u76f4\u904b\u52d5\u5c0e\u81f4\u7684\u5287\u70c8\u5929\u6c23\u73fe\u8c61\uff1a\n",
    "- \u96f7\u66b4\uff08thunderstorms\uff09\n",
    "- \u5f37\u964d\u96e8\n",
    "- \u51b0\u96f9\u3001\u9f8d\u6372\u98a8\n",
    "\n",
    "\u9810\u5831\u5c0d\u6d41\u975e\u5e38\u91cd\u8981\uff0c\u4f46\u50b3\u7d71\u6578\u503c\u6a21\u5f0f\u7684\u89e3\u6790\u5ea6\u4e0d\u8db3\u3002\u6211\u5011\u5e0c\u671b\u7528 ML \u5f9e\u5927\u5c3a\u5ea6\u8b8a\u6578\u9810\u6e2c\u5c0f\u5c3a\u5ea6\u5c0d\u6d41\u3002\n",
    "\n",
    "### \u4efb\u52d9\u5b9a\u7fa9\n",
    "\n",
    "**\u8f38\u5165\uff08Features\uff09**\uff1a\n",
    "- CAPE\uff08Convective Available Potential Energy\uff09\uff1a\u5c0d\u6d41\u53ef\u7528\u4f4d\u80fd\n",
    "- CIN\uff08Convective Inhibition\uff09\uff1a\u5c0d\u6d41\u6291\u5236\n",
    "- K-index\uff1a\u4e0d\u7a69\u5b9a\u6307\u6578\n",
    "- BLH\uff08Boundary Layer Height\uff09\uff1a\u908a\u754c\u5c64\u9ad8\u5ea6\n",
    "\n",
    "**\u8f38\u51fa\uff08Label\uff09**\uff1a\n",
    "- \u4e8c\u5143\u5206\u985e\uff1a\u662f\u5426\u767c\u751f\u5c0d\u6d41\uff080 or 1\uff09\n",
    "\n",
    "### Label \u7684\u5b9a\u7fa9\n",
    "\n",
    "\u5be6\u52d9\u4e0a\uff0c\u5c0d\u6d41\u7684\u5b9a\u7fa9\u53ef\u4ee5\u662f\uff1a\n",
    "- \u96f7\u9054\u56de\u6ce2 > 40 dBZ\uff08\u9700\u8981\u96f7\u9054\u8cc7\u6599\uff09\n",
    "- \u964d\u96e8\u5f37\u5ea6 > 10 mm/hr\uff08\u9700\u8981\u96e8\u91cf\u8cc7\u6599\uff09\n",
    "- **\u7c21\u5316\u7248**\uff1aCAPE > \u67d0\u500b\u95be\u503c + CIN < \u67d0\u500b\u95be\u503c\n",
    "\n",
    "\u9019\u500b workshop \u6211\u5011\u7528\u7c21\u5316\u7248\uff0c\u91cd\u9ede\u662f\u5c55\u793a\u6d41\u7a0b\uff0c\u4e0d\u662f\u9810\u5831\u7cbe\u5ea6\u3002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. \u6e96\u5099\u8cc7\u6599\u8207\u5efa\u7acb Labels\n",
    "\n",
    "### 2.1 \u8f09\u5165\u8cc7\u6599"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u8f09\u5165 2019 \u5e74\u8cc7\u6599\uff08\u6216\u4f7f\u7528\u524d\u9762\u5132\u5b58\u7684\u512a\u5316\u7248\uff09\n",
    "ds = catalog.era5_2019.to_dask()\n",
    "\n",
    "# Resample \u5230 daily \u4ee5\u6e1b\u5c11\u8cc7\u6599\u91cf\n",
    "# \u5c0d\u65bc ML\uff0c\u6211\u5011\u901a\u5e38\u4e0d\u9700\u8981 hourly \u89e3\u6790\u5ea6\n",
    "ds_daily = ds.resample(time='1D').mean()\n",
    "\n",
    "print(\"Dataset:\")\n",
    "print(ds_daily)\n",
    "print()\n",
    "print(f\"Shape: {ds_daily['cape'].shape}\")\n",
    "print(f\"Total size: {ds_daily.nbytes / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 \u5efa\u7acb\u5c0d\u6d41 Label\n",
    "\n",
    "\u6211\u5011\u5b9a\u7fa9\u5c0d\u6d41\u767c\u751f\u7684\u689d\u4ef6\uff1a\n",
    "- CAPE > 1000 J/kg\uff08\u6709\u8db3\u5920\u7684\u4e0d\u7a69\u5b9a\u80fd\u91cf\uff09\n",
    "- CIN > -50 J/kg\uff08\u6291\u5236\u4e0d\u6703\u592a\u5f37\uff09\n",
    "\n",
    "\u9019\u500b\u95be\u503c\u662f\u7c21\u5316\u7684\uff0c\u5be6\u52d9\u4e0a\u9700\u8981\u6839\u64da\u7576\u5730\u6c23\u5019\u8abf\u6574\u3002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u5efa\u7acb binary label\n",
    "convection_flag = (\n",
    "    (ds_daily['cape'] > 1000) & \n",
    "    (ds_daily['cin'] > -50)\n",
    ").astype(np.float32)  # \u8f49\u70ba float32 \u4ee5\u4fbf\u8207 features \u76f8\u5bb9\n",
    "\n",
    "# \u52a0\u5165 Dataset\n",
    "ds_daily['convection_flag'] = convection_flag\n",
    "\n",
    "print(\"Convection flag:\")\n",
    "print(ds_daily['convection_flag'])\n",
    "print()\n",
    "\n",
    "# \u6aa2\u67e5 class balance\n",
    "flag_mean = convection_flag.mean().compute()\n",
    "print(f\"Convection occurrence rate: {flag_mean.values * 100:.2f}%\")\n",
    "print(f\"  Class 0 (no convection): {(1 - flag_mean.values) * 100:.2f}%\")\n",
    "print(f\"  Class 1 (convection): {flag_mean.values * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Imbalance\n",
    "\n",
    "\u5982\u679c\u5c0d\u6d41\u767c\u751f\u7387\u5f88\u4f4e\uff08\u4f8b\u5982 < 10%\uff09\uff0c\u9019\u662f\u5178\u578b\u7684 imbalanced classification problem\u3002\n",
    "\n",
    "\u8655\u7406\u65b9\u6cd5\uff08\u672c workshop \u4e0d\u6df1\u5165\u5be6\u4f5c\uff09\uff1a\n",
    "1. **Weighted loss**\uff1a\u7d66\u5c11\u6578\u985e\u66f4\u9ad8\u6b0a\u91cd\n",
    "2. **Oversampling**\uff1a\u591a\u63a1\u6a23\u5c0d\u6d41\u4e8b\u4ef6\n",
    "3. **Focal loss**\uff1a\u5c08\u6ce8\u65bc\u96e3\u5206\u985e\u7684\u6a23\u672c\n",
    "\n",
    "\u9019\u88e1\u6211\u5011\u5148\u7528\u7c21\u55ae\u7684 cross-entropy loss\uff0c\u91cd\u9ede\u662f\u6d41\u7a0b\u3002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 \u9078\u53d6\u7279\u5b9a\u5340\u57df\u8207\u6642\u9593\u6bb5\n",
    "\n",
    "\u70ba\u4e86\u52a0\u901f\u793a\u7bc4\uff0c\u6211\u5011\u9078\u53d6\uff1a\n",
    "- \u6642\u9593\uff1a2019 \u5e74 6-8 \u6708\uff08\u590f\u5b63\uff0c\u5c0d\u6d41\u65fa\u76db\uff09\n",
    "- \u7a7a\u9593\uff1a20-30\u00b0N, 110-125\u00b0E\uff08\u83ef\u5357\u5730\u5340\uff09"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u9078\u53d6\u5b50\u96c6\n",
    "ds_subset = ds_daily.sel(\n",
    "    time=slice('2019-07-01', '2019-07-15')  # Demo: \u53ea\u7528\u534a\u500b\u6708,\n",
    "    latitude=slice(22, 28)  # Demo: \u66f4\u5c0f\u5340\u57df,\n",
    "    longitude=slice(115, 122)  # Demo: \u66f4\u5c0f\u5340\u57df\n",
    ")\n",
    "\n",
    "print(\"Subset for training:\")\n",
    "print(ds_subset)\n",
    "print()\n",
    "print(f\"Time steps: {len(ds_subset.time)}\")\n",
    "print(f\"Spatial shape: {len(ds_subset.latitude)} x {len(ds_subset.longitude)}\")\n",
    "print(f\"Total size: {ds_subset.nbytes / 1e6:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. \u8cc7\u6599\u5206\u5272\uff1aTrain / Val / Test\n",
    "\n",
    "### \u6642\u9593\u5e8f\u5217\u5206\u5272\u7684\u91cd\u8981\u6027\n",
    "\n",
    "\u5c0d\u65bc\u6642\u9593\u5e8f\u5217\u8cc7\u6599\uff0c**\u4e0d\u80fd\u96a8\u6a5f\u5206\u5272**\uff01\n",
    "\n",
    "\u539f\u56e0\uff1a\n",
    "- \u76f8\u9130\u6642\u9593\u9ede\u9ad8\u5ea6\u76f8\u95dc\uff08temporal autocorrelation\uff09\n",
    "- \u96a8\u6a5f\u5206\u5272\u6703\u300c\u6d29\u9732\u672a\u4f86\u8cc7\u8a0a\u300d\u5230\u8a13\u7df4\u96c6\n",
    "- \u6a21\u578b\u6703\u904e\u5ea6\u64ec\u5408\u77ed\u671f\u8b8a\u5316\n",
    "\n",
    "\u6b63\u78ba\u505a\u6cd5\uff1a**\u6309\u6642\u9593\u9806\u5e8f\u5206\u5272**\n",
    "- Training: \u524d 70%\n",
    "- Validation: \u4e2d\u9593 15%\n",
    "- Test: \u6700\u5f8c 15%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u8a08\u7b97\u5206\u5272\u9ede\n",
    "n_total = len(ds_subset.time)\n",
    "n_train = int(n_total * 0.7)\n",
    "n_val = int(n_total * 0.15)\n",
    "\n",
    "# \u6642\u9593\u5e8f\u5217\u5206\u5272\n",
    "train_ds = ds_subset.isel(time=slice(0, n_train))\n",
    "val_ds = ds_subset.isel(time=slice(n_train, n_train + n_val))\n",
    "test_ds = ds_subset.isel(time=slice(n_train + n_val, None))\n",
    "\n",
    "print(\"Data split:\")\n",
    "print(f\"  Training: {len(train_ds.time)} days ({train_ds.time.values[0]} to {train_ds.time.values[-1]})\")\n",
    "print(f\"  Validation: {len(val_ds.time)} days ({val_ds.time.values[0]} to {val_ds.time.values[-1]})\")\n",
    "print(f\"  Test: {len(test_ds.time)} days ({test_ds.time.values[0]} to {test_ds.time.values[-1]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. xbatcher\uff1a\u7522\u751f\u6642\u7a7a Patches\n",
    "\n",
    "### \u4ec0\u9ebc\u662f\u6642\u7a7a Batch\uff1f\n",
    "\n",
    "\u50b3\u7d71 ML \u7684 batch\uff1a\n",
    "- \u5f9e N \u500b\u6a23\u672c\u4e2d\u96a8\u6a5f\u9078 B \u500b\n",
    "- \u6bcf\u500b\u6a23\u672c\u662f\u7368\u7acb\u7684 feature vector\n",
    "\n",
    "\u6642\u7a7a batch\uff1a\n",
    "- \u5f9e 3D/4D array \u4e2d\u5207\u51fa\u5c0f\u7684\u300cpatches\u300d\n",
    "- \u6bcf\u500b patch \u5305\u542b\u6642\u9593\u548c\u7a7a\u9593\u7dad\u5ea6\n",
    "- \u4fdd\u7559\u6642\u7a7a\u7d50\u69cb\uff08\u5c0d CNN/RNN \u5f88\u91cd\u8981\uff09\n",
    "\n",
    "### xbatcher \u7684\u8a2d\u8a08\n",
    "\n",
    "xbatcher \u63d0\u4f9b\u5169\u968e\u6bb5\u6d41\u7a0b\uff1a\n",
    "\n",
    "**Stage 1: BatchGenerator**\n",
    "- \u5b9a\u7fa9\u5982\u4f55\u5f9e Xarray Dataset \u5207\u51fa batches\n",
    "- \u6307\u5b9a `input_dims`\uff08\u7a7a\u9593\u5927\u5c0f\uff09\u548c `batch_dims`\uff08\u6642\u9593\u5927\u5c0f\uff09\n",
    "- \u4ecd\u7136\u662f **lazy** \u7684\uff08\u4e0d\u6703\u5be6\u969b\u8b80\u53d6\u8cc7\u6599\uff09\n",
    "\n",
    "**Stage 2: MapDataset**\n",
    "- \u5c07 BatchGenerator \u5305\u88dd\u6210 PyTorch Dataset\n",
    "- \u8655\u7406\u5f9e Xarray \u2192 NumPy \u2192 Tensor \u7684\u8f49\u63db\n",
    "- \u53ef\u4ee5\u642d\u914d DataLoader \u505a shuffling\u3001multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Stage 1: \u5275\u5efa BatchGenerator\n",
    "\n",
    "\u6211\u5011\u9700\u8981**\u5206\u5225**\u70ba features \u548c labels \u5275\u5efa BatchGenerator\u3002\n",
    "\n",
    "#### \u53c3\u6578\u8aaa\u660e\n",
    "\n",
    "- **input_dims**: \u7a7a\u9593\u7dad\u5ea6\u7684\u5927\u5c0f\uff08\u4e0d\u6703\u6cbf\u8457\u9019\u4e9b\u7dad\u5ea6\u5207\u5206\uff09\n",
    "  - \u4f8b\u5982 `{'latitude': 16, 'longitude': 16}` \u8868\u793a\u6bcf\u500b patch \u662f 16x16\n",
    "  - \u5982\u679c\u8cc7\u6599\u6709 40 \u500b latitude \u9ede\uff0c\u6703\u7522\u751f 40/16 = 2.5 \u2192 3 \u500b patches\uff08\u6709 overlap\uff09\n",
    "\n",
    "- **batch_dims**: \u6703\u5207\u5206\u7684\u7dad\u5ea6\uff08\u901a\u5e38\u662f\u6642\u9593\uff09\n",
    "  - \u4f8b\u5982 `{'time': 32}` \u8868\u793a\u6bcf\u500b batch \u5305\u542b 32 \u500b\u6642\u9593\u6b65\n",
    "  - \u5982\u679c\u8cc7\u6599\u6709 100 \u5929\uff0c\u6703\u7522\u751f 100/32 \u2248 3 \u500b batches\n",
    "\n",
    "- **preload_batch**: \u662f\u5426\u9810\u5148\u8f09\u5165\u6574\u500b batch \u5230\u8a18\u61b6\u9ad4\n",
    "  - `False`\uff08\u63a8\u85a6\uff09\uff1a\u4fdd\u6301 lazy\uff0c\u53ea\u5728\u8fed\u4ee3\u6642\u8f09\u5165\n",
    "  - `True`\uff1a\u6703\u9810\u5148 .compute()\uff0c\u53ef\u80fd\u8a18\u61b6\u9ad4\u4e0d\u8db3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u5b9a\u7fa9 feature \u8b8a\u6578\n",
    "feature_vars = ['cape', 'cin', 'k_index', 'blh']\n",
    "\n",
    "# Stage 1a: \u70ba features \u5275\u5efa BatchGenerator\n",
    "X_bgen = xbatcher.BatchGenerator(\n",
    "    train_ds[feature_vars],\n",
    "    input_dims={'latitude': 12, 'longitude': 12}  # Demo: \u66f4\u5c0f patch,  # 16x16 \u7a7a\u9593 patches\n",
    "    batch_dims={'time': 16}  # Demo: \u66f4\u5c0f batch,                       # 32 time steps per batch\n",
    "    preload_batch=False  # \u4fdd\u6301 lazy evaluation\n",
    ")\n",
    "\n",
    "# Stage 1b: \u70ba labels \u5275\u5efa BatchGenerator\n",
    "y_bgen = xbatcher.BatchGenerator(\n",
    "    train_ds['convection_flag'],\n",
    "    input_dims={'latitude': 12, 'longitude': 12}  # Demo: \u66f4\u5c0f patch,\n",
    "    batch_dims={'time': 16}  # Demo: \u66f4\u5c0f batch,\n",
    "    preload_batch=False\n",
    ")\n",
    "\n",
    "print(\"BatchGenerators created:\")\n",
    "print(f\"  X_bgen: {len(list(X_bgen))} batches\")\n",
    "print(f\"  y_bgen: {len(list(y_bgen))} batches\")\n",
    "print()\n",
    "print(\"Note: \u4e0a\u9762\u7684 list() \u6703\u5be6\u969b\u8fed\u4ee3\uff0c\u53ea\u662f\u70ba\u4e86\u8a08\u6578\u3002\")\n",
    "print(\"      \u5be6\u969b\u4f7f\u7528\u6642\u4e0d\u9700\u8981\u9019\u6a23\u505a\u3002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 \u6aa2\u8996\u55ae\u4e00 Batch \u7684\u7d50\u69cb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u91cd\u65b0\u5275\u5efa\uff08\u56e0\u70ba generator \u5df2\u7d93\u88ab\u6d88\u8017\u4e86\uff09\n",
    "X_bgen = xbatcher.BatchGenerator(\n",
    "    train_ds[feature_vars],\n",
    "    input_dims={'latitude': 12, 'longitude': 12}  # Demo: \u66f4\u5c0f patch,\n",
    "    batch_dims={'time': 16}  # Demo: \u66f4\u5c0f batch,\n",
    "    preload_batch=False\n",
    ")\n",
    "\n",
    "# \u53d6\u5f97\u7b2c\u4e00\u500b batch\n",
    "first_batch = next(iter(X_bgen))\n",
    "\n",
    "print(\"First batch (still lazy):\")\n",
    "print(first_batch)\n",
    "print()\n",
    "print(f\"Dimensions: {first_batch.dims}\")\n",
    "print(f\"Shape: {first_batch.dims}\")\n",
    "print(f\"Variables: {list(first_batch.data_vars)}\")\n",
    "print()\n",
    "print(f\"CAPE shape in this batch: {first_batch['cape'].shape}\")\n",
    "print(f\"Type: {type(first_batch['cape'].data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \u7406\u89e3 Batch Shape\n",
    "\n",
    "\u539f\u59cb\u8cc7\u6599\uff1a`(time, latitude, longitude)`\n",
    "- time: \u4f8b\u5982 64 \u5929\n",
    "- latitude: 40 \u9ede\n",
    "- longitude: 60 \u9ede\n",
    "\n",
    "\u7d93\u904e xbatcher\uff1a`(time, latitude, longitude)`\n",
    "- time: 32\uff08batch_dims\uff09\n",
    "- latitude: 16\uff08input_dims\uff09\n",
    "- longitude: 16\uff08input_dims\uff09\n",
    "\n",
    "\u9019\u500b shape \u6703\u88ab\u9001\u5165 CNN\u3002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stage 2: PyTorch \u6574\u5408\n",
    "\n",
    "### 5.1 \u4f7f\u7528 xbatcher.loaders.torch.MapDataset\n",
    "\n",
    "**\u91cd\u8981**\uff1a\u9019\u662f xbatcher \u5b98\u65b9\u63d0\u4f9b\u7684 PyTorch \u6574\u5408\u65b9\u5f0f\u3002\n",
    "\n",
    "\u4e0d\u8981\u81ea\u5df1\u5beb `Dataset` wrapper\uff01xbatcher \u5df2\u7d93\u8655\u7406\u597d\u4e86\uff1a\n",
    "- Xarray \u2192 NumPy \u8f49\u63db\n",
    "- NumPy \u2192 Tensor \u8f49\u63db\n",
    "- \u7dad\u5ea6\u9806\u5e8f\u8abf\u6574\uff08Xarray \u662f (time, lat, lon)\uff0cPyTorch \u6163\u4f8b\u662f (batch, channel, height, width)\uff09\n",
    "- Lazy loading \u7ba1\u7406"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u91cd\u65b0\u5275\u5efa BatchGenerators\uff08\u78ba\u4fdd\u6c92\u88ab\u6d88\u8017\uff09\n",
    "X_bgen = xbatcher.BatchGenerator(\n",
    "    train_ds[feature_vars],\n",
    "    input_dims={'latitude': 12, 'longitude': 12}  # Demo: \u66f4\u5c0f patch,\n",
    "    batch_dims={'time': 16}  # Demo: \u66f4\u5c0f batch,\n",
    "    preload_batch=False\n",
    ")\n",
    "\n",
    "y_bgen = xbatcher.BatchGenerator(\n",
    "    train_ds['convection_flag'],\n",
    "    input_dims={'latitude': 12, 'longitude': 12}  # Demo: \u66f4\u5c0f patch,\n",
    "    batch_dims={'time': 16}  # Demo: \u66f4\u5c0f batch,\n",
    "    preload_batch=False\n",
    ")\n",
    "\n",
    "# Stage 2: \u4f7f\u7528\u5b98\u65b9\u7684 MapDataset\n",
    "train_dataset = xbatcher.loaders.torch.MapDataset(\n",
    "    X_bgen,  # features\n",
    "    y_bgen   # labels\n",
    ")\n",
    "\n",
    "print(f\"PyTorch Dataset created: {len(train_dataset)} batches\")\n",
    "print(f\"Type: {type(train_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 \u6aa2\u8996 Dataset \u56de\u50b3\u7684\u8cc7\u6599\n",
    "\n",
    "MapDataset \u56de\u50b3 `(X, y)` tuple\uff0c\u5176\u4e2d\uff1a\n",
    "- X: Tensor of shape `(batch_dim, n_features, height, width)`\n",
    "- y: Tensor of shape `(batch_dim, height, width)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u53d6\u5f97\u4e00\u500b\u6a23\u672c\n",
    "X_sample, y_sample = train_dataset[0]\n",
    "\n",
    "print(\"Sample from Dataset:\")\n",
    "print(f\"  X type: {type(X_sample)}\")\n",
    "print(f\"  X shape: {X_sample.shape}\")\n",
    "print(f\"  X dtype: {X_sample.dtype}\")\n",
    "print()\n",
    "print(f\"  y type: {type(y_sample)}\")\n",
    "print(f\"  y shape: {y_sample.shape}\")\n",
    "print(f\"  y dtype: {y_sample.dtype}\")\n",
    "print()\n",
    "print(\"Shape interpretation:\")\n",
    "print(f\"  X: (time={X_sample.shape[0]}, features={X_sample.shape[1]}, lat={X_sample.shape[2]}, lon={X_sample.shape[3]})\")\n",
    "print(f\"  y: (time={y_sample.shape[0]}, lat={y_sample.shape[1]}, lon={y_sample.shape[2]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 \u5275\u5efa DataLoader\n",
    "\n",
    "**\u95dc\u9375\u53c3\u6578**\uff1a`batch_size=None`\n",
    "\n",
    "\u70ba\u4ec0\u9ebc\uff1f\n",
    "- xbatcher \u5df2\u7d93\u5b9a\u7fa9\u4e86 batch\uff08\u900f\u904e `batch_dims`\uff09\n",
    "- DataLoader \u7684 `batch_size` \u662f\u7528\u4f86\u300c\u628a\u591a\u500b\u6a23\u672c\u7d44\u6210\u4e00\u500b batch\u300d\n",
    "- \u4f46\u6211\u5011\u7684\u300c\u4e00\u500b\u6a23\u672c\u300d\u5df2\u7d93\u662f\u4e00\u500b batch\uff0832 time steps\uff09\n",
    "- \u5982\u679c\u8a2d\u5b9a `batch_size=4`\uff0c\u6703\u8b8a\u6210 `(4, 32, 4, 16, 16)`\uff08\u932f\u8aa4\uff01\uff09\n",
    "\n",
    "**\u6b63\u78ba\u8a2d\u5b9a**\uff1a\n",
    "```python\n",
    "DataLoader(dataset, batch_size=None, ...)\n",
    "```\n",
    "\n",
    "\u9019\u6a23 DataLoader \u53ea\u8ca0\u8cac\uff1a\n",
    "- Shuffling\uff08\u5982\u679c\u9700\u8981\uff09\n",
    "- Multiprocessing\uff08num_workers\uff09\n",
    "- \u4e0d\u6703\u6539\u8b8a batch \u7684 shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u5275\u5efa DataLoader\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=None,  # \u4e0d\u8981\u518d\u589e\u52a0 batch \u7dad\u5ea6\uff01\n",
    "    shuffle=True,     # \u6253\u4e82 batches \u9806\u5e8f\uff08\u4e0d\u662f\u6253\u4e82 batch \u5167\u7684\u9806\u5e8f\uff09\n",
    "    num_workers=2,    # \u5e73\u884c\u8f09\u5165\u8cc7\u6599\n",
    "    multiprocessing_context='forkserver'  # \u907f\u514d Dask client pickle \u554f\u984c\n",
    ")\n",
    "\n",
    "print(f\"DataLoader created: {len(train_loader)} batches\")\n",
    "print()\n",
    "print(\"Parameters:\")\n",
    "print(f\"  batch_size: None (xbatcher already defines batch)\")\n",
    "print(f\"  shuffle: True\")\n",
    "print(f\"  num_workers: 2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 \u6e2c\u8a66 DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u8fed\u4ee3\u53d6\u5f97\u4e00\u500b batch\n",
    "for X_batch, y_batch in train_loader:\n",
    "    print(\"Batch from DataLoader:\")\n",
    "    print(f\"  X: {X_batch.shape}, dtype: {X_batch.dtype}\")\n",
    "    print(f\"  y: {y_batch.shape}, dtype: {y_batch.dtype}\")\n",
    "    print()\n",
    "    print(f\"  X min/max: {X_batch.min():.2f} / {X_batch.max():.2f}\")\n",
    "    print(f\"  y unique values: {torch.unique(y_batch)}\")\n",
    "    break  # \u53ea\u770b\u7b2c\u4e00\u500b batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. \u5b9a\u7fa9 CNN \u6a21\u578b\n",
    "\n",
    "\u6211\u5011\u4f7f\u7528\u4e00\u500b\u7c21\u55ae\u7684 3D CNN\uff08\u6642\u7a7a convolution\uff09\uff1a\n",
    "- Input: `(batch, channels, time, height, width)` = (32, 4, 32, 16, 16)\n",
    "- Output: `(batch, time, height, width)` = (32, 32, 16, 16)\n",
    "\n",
    "\u6a21\u578b\u67b6\u69cb\uff1a\n",
    "1. Conv3D + ReLU + MaxPool\n",
    "2. Conv3D + ReLU + MaxPool  \n",
    "3. Conv3D\uff08output layer\uff0csigmoid \u6fc0\u6d3b\uff09\n",
    "\n",
    "\u9019\u53ea\u662f\u793a\u7bc4\uff0c\u4e0d\u662f state-of-the-art\u3002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConvectionCNN(nn.Module):\n",
    "    def __init__(self, in_channels=4):\n",
    "        super().__init__()\n",
    "        \n",
    "        # 3D Convolutions (time + space)\n",
    "        self.conv1 = nn.Conv3d(in_channels, 16, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv3d(16, 32, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv3d(32, 1, kernel_size=3, padding=1)  # output: 1 channel\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()  # for binary classification\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x: (batch, channels, time, height, width)\n",
    "        # \u4f46\u6211\u5011\u7684\u8cc7\u6599\u662f (time, channels, height, width)\n",
    "        # \u9700\u8981\u8abf\u6574\u7dad\u5ea6\u9806\u5e8f\n",
    "        \n",
    "        # Permute: (time, channels, height, width) -> (1, channels, time, height, width)\n",
    "        # \u52a0\u4e0a batch \u7dad\u5ea6\uff08\u56e0\u70ba batch_size=None\uff0c\u6c92\u6709 batch \u7dad\u5ea6\uff09\n",
    "        if x.dim() == 4:\n",
    "            x = x.unsqueeze(0)  # add batch dim\n",
    "        \n",
    "        # Permute: (batch, time, channels, height, width) -> (batch, channels, time, height, width)\n",
    "        x = x.permute(0, 2, 1, 3, 4)\n",
    "        \n",
    "        # Convolution layers\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.sigmoid(self.conv3(x))\n",
    "        \n",
    "        # Output: (batch, 1, time, height, width)\n",
    "        # Squeeze channel dim and permute back\n",
    "        x = x.squeeze(1)  # (batch, time, height, width)\n",
    "        \n",
    "        # Remove batch dim if added\n",
    "        if x.size(0) == 1:\n",
    "            x = x.squeeze(0)  # (time, height, width)\n",
    "        \n",
    "        return x\n",
    "\n",
    "# \u5275\u5efa\u6a21\u578b\n",
    "model = SimpleConvectionCNN(in_channels=4)\n",
    "print(model)\n",
    "print()\n",
    "\n",
    "# \u8a08\u7b97\u53c3\u6578\u6578\u91cf\n",
    "n_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {n_params:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \u6e2c\u8a66\u6a21\u578b Forward Pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u5275\u5efa dummy input\n",
    "dummy_input = torch.randn(32, 4, 16, 16)  # (time, channels, height, width)\n",
    "\n",
    "# Forward pass\n",
    "with torch.no_grad():\n",
    "    output = model(dummy_input)\n",
    "\n",
    "print(f\"Input shape: {dummy_input.shape}\")\n",
    "print(f\"Output shape: {output.shape}\")\n",
    "print(f\"Output range: [{output.min():.3f}, {output.max():.3f}]\")\n",
    "print()\n",
    "print(\"\u2713 Model forward pass successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. \u8a13\u7df4\u8ff4\u5708\n",
    "\n",
    "### 7.1 \u8a2d\u5b9a\u8a13\u7df4\u53c3\u6578"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u8a2d\u5b9a device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss function\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training config\n",
    "n_epochs = 2  # Demo: \u5feb\u901f\u5c55\u793a\u6d41\u7a0b\n",
    "\n",
    "print(f\"Training configuration:\")\n",
    "print(f\"  Epochs: {n_epochs}\")\n",
    "print(f\"  Optimizer: Adam (lr=0.001)\")\n",
    "print(f\"  Loss: Binary Cross Entropy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 \u8a13\u7df4\u8ff4\u5708"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "history = {'loss': []}\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    n_batches = 0\n",
    "    \n",
    "    for X_batch, y_batch in train_loader:\n",
    "        # Move to device\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(X_batch)\n",
    "        \n",
    "        # Calculate loss\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        # Backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Record\n",
    "        epoch_loss += loss.item()\n",
    "        n_batches += 1\n",
    "    \n",
    "    # Epoch summary\n",
    "    avg_loss = epoch_loss / n_batches\n",
    "    history['loss'].append(avg_loss)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{n_epochs} - Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(\"\\n\u2713 Training complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.3 \u7e6a\u88fd Training Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(range(1, n_epochs+1), history['loss'], marker='o', linewidth=2, markersize=8)\n",
    "plt.xlabel('Epoch', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.title('Training Loss', fontsize=13)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. \u6a21\u578b\u8a55\u4f30\u8207\u8996\u89ba\u5316\n",
    "\n",
    "### 8.1 \u5728 Test Set \u4e0a\u9810\u6e2c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u70ba test set \u5275\u5efa DataLoader\n",
    "X_test_bgen = xbatcher.BatchGenerator(\n",
    "    test_ds[feature_vars],\n",
    "    input_dims={'latitude': 16, 'longitude': 16},\n",
    "    batch_dims={'time': 32},\n",
    "    preload_batch=False\n",
    ")\n",
    "\n",
    "y_test_bgen = xbatcher.BatchGenerator(\n",
    "    test_ds['convection_flag'],\n",
    "    input_dims={'latitude': 16, 'longitude': 16},\n",
    "    batch_dims={'time': 32},\n",
    "    preload_batch=False\n",
    ")\n",
    "\n",
    "test_dataset = xbatcher.loaders.torch.MapDataset(X_test_bgen, y_test_bgen)\n",
    "test_loader = DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=None,\n",
    "    shuffle=False,  # test set \u4e0d shuffle\n",
    "    num_workers=2,\n",
    "    multiprocessing_context='forkserver'\n",
    ")\n",
    "\n",
    "print(f\"Test set: {len(test_loader)} batches\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "model.eval()\n",
    "test_loss = 0.0\n",
    "predictions = []\n",
    "targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch = X_batch.to(device)\n",
    "        y_batch = y_batch.to(device)\n",
    "        \n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        \n",
    "        test_loss += loss.item()\n",
    "        predictions.append(outputs.cpu())\n",
    "        targets.append(y_batch.cpu())\n",
    "\n",
    "avg_test_loss = test_loss / len(test_loader)\n",
    "print(f\"Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "# Concatenate all predictions\n",
    "predictions = torch.cat(predictions, dim=0)\n",
    "targets = torch.cat(targets, dim=0)\n",
    "\n",
    "print(f\"\\nPredictions shape: {predictions.shape}\")\n",
    "print(f\"Targets shape: {targets.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 \u8a08\u7b97\u5206\u985e\u6307\u6a19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# \u8f49\u70ba binary predictions (threshold = 0.5)\n",
    "pred_binary = (predictions > 0.5).float()\n",
    "\n",
    "# Flatten for sklearn\n",
    "pred_flat = pred_binary.flatten().numpy()\n",
    "target_flat = targets.flatten().numpy()\n",
    "\n",
    "# Calculate metrics\n",
    "accuracy = accuracy_score(target_flat, pred_flat)\n",
    "precision = precision_score(target_flat, pred_flat, zero_division=0)\n",
    "recall = recall_score(target_flat, pred_flat, zero_division=0)\n",
    "f1 = f1_score(target_flat, pred_flat, zero_division=0)\n",
    "\n",
    "print(\"Classification Metrics:\")\n",
    "print(f\"  Accuracy:  {accuracy:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall:    {recall:.4f}\")\n",
    "print(f\"  F1 Score:  {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.3 \u8996\u89ba\u5316\uff1a\u9810\u6e2c vs \u771f\u5be6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u9078\u53d6\u4e00\u500b\u6642\u9593\u6b65\u9a5f\u548c\u7a7a\u9593 patch \u4f86\u8996\u89ba\u5316\n",
    "t_idx = 10  # \u7b2c 10 \u500b\u6642\u9593\u6b65\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# True labels\n",
    "im1 = axes[0].imshow(targets[t_idx], cmap='RdYlBu_r', vmin=0, vmax=1)\n",
    "axes[0].set_title('Ground Truth', fontsize=12)\n",
    "axes[0].set_xlabel('Longitude')\n",
    "axes[0].set_ylabel('Latitude')\n",
    "plt.colorbar(im1, ax=axes[0])\n",
    "\n",
    "# Predictions (probability)\n",
    "im2 = axes[1].imshow(predictions[t_idx], cmap='RdYlBu_r', vmin=0, vmax=1)\n",
    "axes[1].set_title('Predicted Probability', fontsize=12)\n",
    "axes[1].set_xlabel('Longitude')\n",
    "plt.colorbar(im2, ax=axes[1])\n",
    "\n",
    "# Binary predictions\n",
    "im3 = axes[2].imshow(pred_binary[t_idx], cmap='RdYlBu_r', vmin=0, vmax=1)\n",
    "axes[2].set_title('Binary Prediction (>0.5)', fontsize=12)\n",
    "axes[2].set_xlabel('Longitude')\n",
    "plt.colorbar(im3, ax=axes[2])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. \u4f7f\u7528 xskillscore \u9032\u884c\u7a7a\u9593\u9a57\u8b49\n",
    "\n",
    "### \u70ba\u4ec0\u9ebc\u9700\u8981 xskillscore\uff1f\n",
    "\n",
    "\u50b3\u7d71 ML \u8a55\u4f30\uff08accuracy, F1\uff09\u628a\u6240\u6709\u50cf\u7d20\u7576\u4f5c\u7368\u7acb\u6a23\u672c\uff0c\u5ffd\u7565\u4e86\uff1a\n",
    "- **\u7a7a\u9593\u9023\u7e8c\u6027**\uff1a\u76f8\u9130\u683c\u9ede\u7684\u9810\u6e2c\u61c9\u8a72\u5e73\u6ed1\n",
    "- **\u7a7a\u9593\u5c3a\u5ea6**\uff1a\u5927\u7bc4\u570d\u7684\u932f\u8aa4 vs \u5c0f\u7bc4\u570d\u7684\u932f\u8aa4\n",
    "- **\u7a7a\u9593\u76f8\u95dc**\uff1a\u9810\u6e2c\u7684\u7a7a\u9593\u7d50\u69cb\u662f\u5426\u5408\u7406\uff1f\n",
    "\n",
    "xskillscore \u63d0\u4f9b\u300c\u7a7a\u9593\u611f\u77e5\u300d\u7684\u9a57\u8b49\u6307\u6a19\uff1a\n",
    "- **Spatial correlation**\uff1a\u9810\u6e2c\u5834\u8207\u771f\u5be6\u5834\u7684\u7a7a\u9593\u76f8\u95dc\n",
    "- **RMSE by region**\uff1a\u4e0d\u540c\u5340\u57df\u7684\u8aa4\u5dee\n",
    "- **Fractions Skill Score**\uff1a\u8003\u616e\u7a7a\u9593\u9130\u57df\u7684\u9a57\u8b49\n",
    "\n",
    "### \u70ba\u4ec0\u9ebc xskillscore \u9069\u5408\u9019\u500b workflow\uff1f\n",
    "\n",
    "xskillscore \u76f4\u63a5\u63a5\u53d7 **Xarray DataArray**\uff1a\n",
    "- \u4fdd\u7559\u7d93\u7def\u5ea6\u5ea7\u6a19\n",
    "- \u53ef\u4ee5\u505a\u5340\u57df\u52a0\u6b0a\uff08area-weighted metrics\uff09\n",
    "- \u53ef\u4ee5\u6cbf\u8457\u4e0d\u540c\u7dad\u5ea6\u8a08\u7b97\uff08\u6642\u9593\u3001\u7a7a\u9593\u3001ensemble\uff09\n",
    "\n",
    "\u9019\u5c31\u662f\u70ba\u4ec0\u9ebc\u6211\u5011\u7528 Xarray \u800c\u4e0d\u662f pandas/NumPy \u7684\u539f\u56e0\u4e4b\u4e00\u3002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 \u5c07\u9810\u6e2c\u8f49\u56de Xarray\n",
    "\n",
    "\u6211\u5011\u9700\u8981\u628a PyTorch Tensor \u8f49\u56de Xarray\uff0c\u6062\u5fa9\u5ea7\u6a19\u8cc7\u8a0a\u3002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u6ce8\u610f\uff1a\u9019\u88e1\u662f\u7c21\u5316\u7248\uff0c\u5be6\u52d9\u4e0a\u9700\u8981\u6b63\u78ba\u5c0d\u61c9\u6bcf\u500b patch \u7684\u5ea7\u6a19\n",
    "# \u70ba\u4e86\u793a\u7bc4\uff0c\u6211\u5011\u5047\u8a2d predictions \u548c test_ds \u7684\u7a7a\u9593\u7bc4\u570d\u76f8\u540c\n",
    "\n",
    "# \u53d6\u5f97\u4e00\u500b batch \u7684\u5ea7\u6a19\n",
    "sample_batch = next(iter(X_test_bgen))\n",
    "time_coords = sample_batch['time'].values\n",
    "lat_coords = sample_batch['latitude'].values\n",
    "lon_coords = sample_batch['longitude'].values\n",
    "\n",
    "# \u5275\u5efa Xarray DataArray\n",
    "pred_da = xr.DataArray(\n",
    "    predictions[:len(time_coords)].numpy(),  # \u9650\u5236\u5230\u5be6\u969b\u7684\u6642\u9593\u9577\u5ea6\n",
    "    dims=['time', 'latitude', 'longitude'],\n",
    "    coords={\n",
    "        'time': time_coords,\n",
    "        'latitude': lat_coords,\n",
    "        'longitude': lon_coords\n",
    "    },\n",
    "    name='convection_probability'\n",
    ")\n",
    "\n",
    "target_da = xr.DataArray(\n",
    "    targets[:len(time_coords)].numpy(),\n",
    "    dims=['time', 'latitude', 'longitude'],\n",
    "    coords={\n",
    "        'time': time_coords,\n",
    "        'latitude': lat_coords,\n",
    "        'longitude': lon_coords\n",
    "    },\n",
    "    name='convection_truth'\n",
    ")\n",
    "\n",
    "print(\"Predictions as Xarray:\")\n",
    "print(pred_da)\n",
    "print()\n",
    "print(\"Targets as Xarray:\")\n",
    "print(target_da)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 \u8a08\u7b97\u7a7a\u9593\u76f8\u95dc\u4fc2\u6578"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xskillscore as xs\n",
    "\n",
    "# \u8a08\u7b97\u6bcf\u500b\u6642\u9593\u6b65\u7684\u7a7a\u9593\u76f8\u95dc\n",
    "spatial_corr = xs.pearson_r(pred_da, target_da, dim=['latitude', 'longitude'])\n",
    "\n",
    "print(\"Spatial correlation (per time step):\")\n",
    "print(spatial_corr.values)\n",
    "print()\n",
    "print(f\"Mean spatial correlation: {spatial_corr.mean().values:.4f}\")\n",
    "print(f\"Std: {spatial_corr.std().values:.4f}\")\n",
    "\n",
    "# \u7e6a\u5716\n",
    "plt.figure(figsize=(10, 4))\n",
    "spatial_corr.plot(marker='o')\n",
    "plt.axhline(y=0, color='k', linestyle='--', alpha=0.3)\n",
    "plt.title('Spatial Correlation over Time', fontsize=13)\n",
    "plt.ylabel('Pearson r', fontsize=12)\n",
    "plt.xlabel('Time', fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.3 \u8a08\u7b97\u7a7a\u9593 RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u8a08\u7b97 RMSE\n",
    "rmse = xs.rmse(pred_da, target_da, dim=['time', 'latitude', 'longitude'])\n",
    "\n",
    "print(f\"Overall RMSE: {rmse.values:.4f}\")\n",
    "\n",
    "# \u4e5f\u53ef\u4ee5\u8a08\u7b97\u6bcf\u500b\u683c\u9ede\u7684\u6642\u9593 RMSE\n",
    "rmse_spatial = xs.rmse(pred_da, target_da, dim='time')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "rmse_spatial.plot(cmap='YlOrRd', vmin=0)\n",
    "plt.title('RMSE by Location (averaged over time)', fontsize=13)\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"\u7d05\u8272\u5340\u57df\uff1a\u6a21\u578b\u9810\u6e2c\u8aa4\u5dee\u8f03\u5927\")\n",
    "print(\"\u9ec3\u8272/\u7da0\u8272\uff1a\u9810\u6e2c\u8f03\u6e96\u78ba\")\n",
    "print(\"\u53ef\u4ee5\u5e6b\u52a9\u8b58\u5225\u6a21\u578b\u5728\u54ea\u4e9b\u5730\u7406\u4f4d\u7f6e\u8868\u73fe\u8f03\u5dee\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. \u5b8c\u6574 Workflow \u56de\u9867\n",
    "\n",
    "\u8b93\u6211\u5011\u56de\u9867\u6574\u500b\u5f9e\u300c\u5927\u578b N-D array\u300d\u5230\u300cML \u6a21\u578b\u300d\u7684\u6d41\u7a0b\uff1a\n",
    "\n",
    "```\n",
    "1. \u8cc7\u6599\u5132\u5b58\n",
    "   Zarr (on-disk, chunked)\n",
    "   \u2193\n",
    "   \n",
    "2. \u8cc7\u6599\u8b80\u53d6\n",
    "   intake-xarray + Dask\n",
    "   \u2193 (lazy)\n",
    "   \n",
    "3. \u524d\u8655\u7406\n",
    "   - Resample (hourly \u2192 daily)\n",
    "   - \u5efa\u7acb labels\n",
    "   - \u6642\u9593\u5e8f\u5217\u5206\u5272\n",
    "   \u2193 (still lazy)\n",
    "   \n",
    "4. Batch \u751f\u6210\n",
    "   xbatcher.BatchGenerator\n",
    "   \u2193\n",
    "   \n",
    "5. PyTorch \u6574\u5408\n",
    "   xbatcher.loaders.torch.MapDataset\n",
    "   \u2193\n",
    "   \n",
    "6. \u8cc7\u6599\u8f09\u5165\n",
    "   DataLoader (batch_size=None)\n",
    "   \u2193 (now eager, on-demand)\n",
    "   \n",
    "7. \u6a21\u578b\u8a13\u7df4\n",
    "   PyTorch training loop\n",
    "   \u2193\n",
    "   \n",
    "8. \u9810\u6e2c\u8207\u8a55\u4f30\n",
    "   - \u50b3\u7d71 metrics (accuracy, F1)\n",
    "   - \u7a7a\u9593 metrics (xskillscore)\n",
    "   \u2193\n",
    "   \n",
    "9. \u7d50\u679c\u8996\u89ba\u5316\n",
    "   Xarray + matplotlib\n",
    "```\n",
    "\n",
    "### \u95dc\u9375\u8a2d\u8a08\u539f\u5247\n",
    "\n",
    "1. **Lazy as long as possible**\n",
    "   - \u76f4\u5230 DataLoader \u8fed\u4ee3\u6642\u624d\u5be6\u969b\u8b80\u53d6\u8cc7\u6599\n",
    "   - \u6e1b\u5c11\u8a18\u61b6\u9ad4\u4f54\u7528\n",
    "\n",
    "2. **\u4fdd\u7559\u5143\u8cc7\u6599**\n",
    "   - \u4f7f\u7528 Xarray \u800c\u4e0d\u662f NumPy\n",
    "   - \u5ea7\u6a19\u8cc7\u8a0a\u5c0d\u9a57\u8b49\u548c\u8996\u89ba\u5316\u5f88\u91cd\u8981\n",
    "\n",
    "3. **\u6279\u6b21\u8655\u7406**\n",
    "   - xbatcher \u81ea\u52d5\u8655\u7406\u6642\u7a7a\u5207\u5206\n",
    "   - \u4e0d\u9700\u8981\u624b\u52d5\u7ba1\u7406\u7d22\u5f15\n",
    "\n",
    "4. **\u5e73\u884c\u5316**\n",
    "   - Dask \u8655\u7406\u8cc7\u6599\u8b80\u53d6\u7684\u5e73\u884c\u5316\n",
    "   - DataLoader \u7684 num_workers \u8655\u7406\u524d\u8655\u7406\u5e73\u884c\u5316\n",
    "   - GPU \u8655\u7406\u6a21\u578b\u8a13\u7df4\u5e73\u884c\u5316"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. \u5e38\u898b\u554f\u984c\u8207\u9664\u932f\n",
    "\n",
    "### Q1: DataLoader \u5831\u932f \"batch_size should be None\"\n",
    "\n",
    "**\u539f\u56e0**\uff1axbatcher \u5df2\u7d93\u5b9a\u7fa9\u4e86 batch\uff0c\u4e0d\u61c9\u8a72\u518d\u7528 DataLoader \u7684 batch_size\u3002\n",
    "\n",
    "**\u89e3\u6cd5**\uff1a\n",
    "```python\n",
    "DataLoader(dataset, batch_size=None, ...)  # \u6b63\u78ba\n",
    "DataLoader(dataset, batch_size=4, ...)     # \u932f\u8aa4\uff01\n",
    "```\n",
    "\n",
    "### Q2: Multiprocessing \u5831\u932f \"cannot pickle Client\"\n",
    "\n",
    "**\u539f\u56e0**\uff1aDask Client \u7121\u6cd5\u88ab pickle\uff0c\u4f46 DataLoader \u7684 multiprocessing \u9700\u8981 pickle\u3002\n",
    "\n",
    "**\u89e3\u6cd5**\uff1a\n",
    "```python\n",
    "DataLoader(..., multiprocessing_context='forkserver')  # \u4f7f\u7528 forkserver\n",
    "# \u6216\n",
    "DataLoader(..., num_workers=0)  # \u4e0d\u4f7f\u7528 multiprocessing\n",
    "```\n",
    "\n",
    "### Q3: \u8a18\u61b6\u9ad4\u4e0d\u8db3\uff08OOM\uff09\n",
    "\n",
    "**\u539f\u56e0**\uff1a\n",
    "- Batch \u592a\u5927\uff08\u6642\u9593\u6216\u7a7a\u9593\u7dad\u5ea6\uff09\n",
    "- preload_batch=True\n",
    "- num_workers \u592a\u591a\n",
    "\n",
    "**\u89e3\u6cd5**\uff1a\n",
    "1. \u6e1b\u5c0f batch_dims \u6216 input_dims\n",
    "2. \u78ba\u4fdd preload_batch=False\n",
    "3. \u6e1b\u5c11 num_workers\n",
    "4. \u8abf\u6574 Dask Client \u7684 memory_limit\n",
    "\n",
    "### Q4: \u8a13\u7df4\u5f88\u6162\n",
    "\n",
    "**\u53ef\u80fd\u539f\u56e0**\uff1a\n",
    "- I/O \u74f6\u9838\uff1a\u589e\u52a0 num_workers\n",
    "- Chunk \u592a\u5c0f\uff1a\u8003\u616e rechunk\n",
    "- CPU \u8a08\u7b97\uff1a\u6aa2\u67e5\u662f\u5426\u6b63\u78ba\u4f7f\u7528 GPU\n",
    "\n",
    "**\u9664\u932f**\uff1a\u89c0\u5bdf Dask Dashboard\uff0c\u770b\u6642\u9593\u82b1\u5728\u54ea\u88e1\u3002"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. \u5ef6\u4f38\u65b9\u5411\n",
    "\n",
    "\u9019\u500b workshop \u5c55\u793a\u4e86\u57fa\u790e\u6d41\u7a0b\uff0c\u5be6\u52d9\u4e0a\u53ef\u4ee5\u5ef6\u4f38\uff1a\n",
    "\n",
    "### \u8cc7\u6599\u9762\n",
    "- \u52a0\u5165\u66f4\u591a\u8b8a\u6578\uff08\u6fd5\u5ea6\u3001\u98a8\u5834\u3001\u6eab\u5ea6\u5256\u9762\uff09\n",
    "- \u591a\u8cc7\u6599\u4f86\u6e90\u878d\u5408\uff08ERA5 + \u885b\u661f + \u5730\u9762\u89c0\u6e2c\uff09\n",
    "- \u6642\u9593\u6eef\u5f8c\u7279\u5fb5\uff08t-1, t-2 \u5c0f\u6642\u7684\u8cc7\u6599\uff09\n",
    "\n",
    "### \u6a21\u578b\u9762\n",
    "- \u66f4\u8907\u96dc\u7684\u67b6\u69cb\uff08UNet, ResNet, Transformer\uff09\n",
    "- \u5e8f\u5217\u6a21\u578b\uff08LSTM, GRU\uff09\u7528\u65bc\u6642\u9593\u5e8f\u5217\n",
    "- Ensemble \u6a21\u578b\n",
    "\n",
    "### \u8a13\u7df4\u9762\n",
    "- Class imbalance \u8655\u7406\uff08weighted loss, focal loss\uff09\n",
    "- Data augmentation\uff08spatial flip, rotation\uff09\n",
    "- Transfer learning\uff08\u9810\u8a13\u7df4\u6a21\u578b\uff09\n",
    "\n",
    "### \u9a57\u8b49\u9762\n",
    "- \u66f4\u591a\u7a7a\u9593\u6307\u6a19\uff08Fractions Skill Score, SAL\uff09\n",
    "- Case study\uff08\u5206\u6790\u7279\u5b9a\u4e8b\u4ef6\uff09\n",
    "- \u5340\u57df\u5316\u8a55\u4f30\uff08\u5c71\u5340 vs \u5e73\u5730\uff09"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. \u7e3d\u7d50\n",
    "\n",
    "\u5b8c\u6210\u9019\u500b notebook \u5f8c\uff0c\u4f60\u61c9\u8a72\u80fd\u5920\uff1a\n",
    "\n",
    "- [ ] \u5b9a\u7fa9\u9069\u5408 ML \u7684\u6c23\u8c61\u4efb\u52d9\n",
    "- [ ] \u5efa\u7acb\u6709\u610f\u7fa9\u7684 labels\n",
    "- [ ] \u4f7f\u7528 xbatcher \u7522\u751f\u6642\u7a7a batches\n",
    "- [ ] \u6b63\u78ba\u6574\u5408 xbatcher \u8207 PyTorch\n",
    "- [ ] \u8a2d\u5b9a DataLoader\uff08batch_size=None!\uff09\n",
    "- [ ] \u8a13\u7df4\u4e00\u500b\u7c21\u55ae\u7684 CNN \u6a21\u578b\n",
    "- [ ] \u4f7f\u7528 xskillscore \u9032\u884c\u7a7a\u9593\u9a57\u8b49\n",
    "- [ ] \u7406\u89e3\u5b8c\u6574\u7684 out-of-core ML workflow\n",
    "\n",
    "### \u6838\u5fc3\u8981\u9ede\n",
    "\n",
    "1. **xbatcher \u7684\u5169\u968e\u6bb5\u8a2d\u8a08\u662f\u95dc\u9375**\n",
    "   - BatchGenerator \u2192 MapDataset\n",
    "   - \u4e0d\u8981\u81ea\u5df1\u5beb Dataset wrapper\n",
    "\n",
    "2. **batch_size=None \u907f\u514d\u7dad\u5ea6\u932f\u8aa4**\n",
    "   - xbatcher \u5df2\u7d93\u5b9a\u7fa9 batch\n",
    "   - DataLoader \u53ea\u8ca0\u8cac shuffling \u548c multiprocessing\n",
    "\n",
    "3. **\u4fdd\u7559\u7a7a\u9593\u8cc7\u8a0a\u5f88\u91cd\u8981**\n",
    "   - \u8f49\u56de Xarray \u505a\u9a57\u8b49\n",
    "   - \u7a7a\u9593\u76f8\u95dc\u6027\u662f\u6c23\u8c61\u9810\u5831\u7684\u6838\u5fc3\n",
    "\n",
    "4. **Lazy evaluation \u8cab\u7a7f\u6574\u500b\u6d41\u7a0b**\n",
    "   - \u5f9e Zarr \u8b80\u53d6\u5230 DataLoader \u90fd\u662f lazy\n",
    "   - \u53ea\u5728\u9700\u8981\u6642\u624d\u8f09\u5165\u8cc7\u6599\n",
    "\n",
    "\u9019\u500b\u5de5\u4f5c\u6d41\u7a0b\u53ef\u4ee5\u64f4\u5c55\u5230\uff1a\n",
    "- \u66f4\u5927\u7684\u8cc7\u6599\u96c6\uff08TB \u7d1a\u5225\uff09\n",
    "- \u66f4\u8907\u96dc\u7684\u6a21\u578b\uff08\u6df1\u5ea6\u5b78\u7fd2\uff09\n",
    "- \u5206\u6563\u5f0f\u8a13\u7df4\uff08\u591a GPU\u3001\u591a\u7bc0\u9ede\uff09\n",
    "\n",
    "\u91cd\u9ede\u662f**\u7406\u89e3\u539f\u7406**\uff0c\u800c\u4e0d\u662f\u8a18\u4f4f API\u3002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \u95dc\u9589 Dask Client\n",
    "# client.close()\n",
    "\n",
    "print(\"Workshop completed! \ud83c\udf89\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}